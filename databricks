df1 = pd.DataFrame({
    'ID': [1, 2, 3, 4],
    'Value': ['A', 'B', 'C', 'D']
})

df2 = pd.DataFrame({
    'ID': [1, 2, 3, 5],
    'Value': ['A', 'B', 'C', 'E']
})

# Merge dataframes on 'ID' column
merged_df = pd.merge(df1, df2, on='ID', suffixes=('_df1', '_df2'))

# Filter rows where 'Value' columns do not match
mismatches = merged_df[merged_df['Value_df1'] != merged_df['Value_df2']]

# Print the mismatches
print("Mismatches:")
print(mismatches)



df1['order_amount'] = pd.to_numeric(df1['order_amount'], errors='coerce')

import pandas as pd

# Sample DataFrames
df1 = pd.DataFrame({
    'customer': ['Alice', 'Bob', 'Charlie', 'David'],
    'order_amount': [100, 200, 300, 400]
})

df2 = pd.DataFrame({
    'customer': ['Charlie', 'David', 'Eva', 'Frank'],
    'order_amount': [300, 400, 500, 600]
})

# Perform a full outer merge with an indicator column
merged_df = df1.merge(df2, on=['customer', 'order_amount'], how='outer', indicator=True)

# Identify rows only in df1
only_in_df1 = merged_df[merged_df['_merge'] == 'left_only']

# Identify rows only in df2
only_in_df2 = merged_df[merged_df['_merge'] == 'right_only']

# Identify rows where `customer` exists in both but `order_amount` differs
common_customers = df1.merge(df2, on='customer', how='inner')
mismatched_amounts = common_customers[common_customers['order_amount_x'] != common_customers['order_amount_y']]

# Print the results
print("Customers and amounts in df1 but not in df2:")
print(only_in_df1.drop(columns=['_merge']))

print("\nCustomers and amounts in df2 but not in df1:")
print(only_in_df2.drop(columns=['_merge']))

print("\nCustomers with mismatched amounts:")
print(mismatched_amounts[['customer', 'order_amount_x', 'order_amount_y']])



from databricks.connect import DatabricksSession

spark = DatabricksSession.builder.profile("profilename").getOrCreate()

df = spark.read.table("table name")
df.show(5)


-------------------
 databricks auth login --configure-cluster --host <>
----------------
import requests
import json
from databricks_cli.sdk.api_client import ApiClient

# Define your Databricks host and token
databricks_host = "https://<your-databricks-instance>.azuredatabricks.net"
databricks_token = "<your-databricks-token>"

# Create an API client
api_client = ApiClient(host=databricks_host, token=databricks_token)

# Define your query
query = """
SELECT *
FROM my_table
LIMIT 10
"""

# Run the query
response = api_client.perform_query("my_workspace", query)

# Print the results
print(json.dumps(response, indent=2))
